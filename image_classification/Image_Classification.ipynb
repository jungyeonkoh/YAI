{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 소녀시대 멤버 얼굴 분류기\n",
    "\n",
    "1. 데이터셋 수집: 윤아와 써니 사진 1000여장을 크롤링을 통해 구하였다. \n",
    "2. 이미지 파일 수치화\n",
    "3. 이미지데이터셋 클래스 생성\n",
    "4. 모델구축\n",
    "5. 학습 및 검증\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터셋 수집 및 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "import os\n",
    "from urllib.request import urlretrieve\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 크롤링\n",
    "\n",
    "keyword = input(\"keyword: \")\n",
    "url = \"https://search.naver.com/search.naver?where=image&sm=tab_jum&query={}\".format(keyword)\n",
    "\n",
    "print(\"접속중\")\n",
    "driver = webdriver.Chrome(\"/Users/jungyeonkoh/Downloads/chromedriver\")\n",
    "driver.implicitly_wait(30)\n",
    "driver.get(url)\n",
    "\n",
    "# 페이지 스크롤 다운\n",
    "body = driver.find_element_by_css_selector(\"body\")\n",
    "for i in range(150):\n",
    "    body.send_keys(Keys.PAGE_DOWN)\n",
    "    time.sleep(1)\n",
    "\n",
    "imgs = driver.find_elements_by_css_selector(\"img._img\")\n",
    "result = []\n",
    "for img in tqdm(imgs):\n",
    "    if \"http\" in img.get_attribute(\"src\"):\n",
    "        result.append(img.get_attribute(\"src\"))\n",
    "\n",
    "driver.close()\n",
    "print(\"수집완료\")\n",
    "\n",
    "# 폴더 생성\n",
    "print(\"폴더생성\")\n",
    "if not os.path.isdir(\"/Users/jungyeonkoh/Desktop/YAI/Crawling_Images/{}\".format(keyword)):\n",
    "    os.mkdir(\"/Users/jungyeonkoh/Desktop/Crawling_Images/{}\".format(keyword))\n",
    "\n",
    "# 다운로드\n",
    "for index, link in tqdm(enumerate(result)):\n",
    "    start = link.rfind('.')\n",
    "    end = link.rfind('&')\n",
    "    filetype = link[start:end]\n",
    "    \n",
    "    urlretrieve(link, \"/Users/jungyeonkoh/Desktop/YAI/Crawling_Images/{}/{}{}{}\".format(keyword, keyword, index, filetype))\n",
    "    time.sleep(1)\n",
    "\n",
    "print(\"다운로드완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# 불필요한 이미지 삭제 후 라벨링\n",
    "file_path = \"/Users/jungyeonkoh/Desktop/YAI/Crawling_Images/티파니\"\n",
    "test_dir = \"/Users/jungyeonkoh/Desktop/YAI/Crawling_Images/윤아_testdata\"\n",
    "file_names = os.listdir(file_path)\n",
    "\n",
    "i = 1\n",
    "for name in file_names:\n",
    "    start = name.rfind('.')\n",
    "    filetype = name[start:]\n",
    "    src = os.path.join(file_path, name)\n",
    "    dst = str(i) + \".jpg\"\n",
    "    dst = os.path.join(file_path, dst)\n",
    "    os.rename(src, dst)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crop_Face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from googleapiclient import  discovery\n",
    "from oauth2client.client  import GoogleCredentials\n",
    "import sys\n",
    "import io\n",
    "import base64\n",
    "from PIL import Image\n",
    "from PIL import ImageDraw\n",
    "from genericpath import isfile\n",
    "import os\n",
    "import hashlib\n",
    "from oauth2client.service_account import ServiceAccountCredentials\n",
    "import imageio\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"]='/Users/jungyeonkoh/Downloads/My First Project-500b6dfc89fb.json'\n",
    "\n",
    "def detect_faces(path):\n",
    "    \"\"\"Detects faces in an image.\"\"\"\n",
    "    from google.cloud import vision\n",
    "    import io\n",
    "    client = vision.ImageAnnotatorClient()\n",
    "\n",
    "    with io.open(path, 'rb') as image_file:\n",
    "        content = image_file.read()\n",
    "\n",
    "    image = vision.types.Image(content=content)\n",
    "\n",
    "    response = client.face_detection(image=image)\n",
    "    faces = response.face_annotations\n",
    "    \n",
    "    \n",
    "    # Names of likelihood from google.cloud.vision.enums\n",
    "    likelihood_name = ('UNKNOWN', 'VERY_UNLIKELY', 'UNLIKELY', 'POSSIBLE',\n",
    "                       'LIKELY', 'VERY_LIKELY')\n",
    "    # print('Faces:')\n",
    "    \"\"\"\n",
    "    for face in faces:\n",
    "        # print('anger: {}'.format(likelihood_name[face.anger_likelihood]))\n",
    "        # print('joy: {}'.format(likelihood_name[face.joy_likelihood]))\n",
    "        # print('surprise: {}'.format(likelihood_name[face.surprise_likelihood]))\n",
    "\n",
    "        vertices = ([(vertex.x, vertex.y)\n",
    "                    for vertex in face.bounding_poly.vertices])\n",
    "\n",
    "        # print('face bounds: {}'.format(','.join(vertices)))\n",
    "    \"\"\"\n",
    "    vertices = ([(vertex.x, vertex.y) for vertex in faces[0].bounding_poly.vertices])\n",
    "    \n",
    "    if response.error.message:\n",
    "        raise Exception(\n",
    "            '{}\\nFor more info on error messages, check: '\n",
    "            'https://cloud.google.com/apis/design/errors'.format(\n",
    "                response.error.message))\n",
    "\n",
    "    return vertices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_face(path, label):\n",
    "    for i, image in enumerate(os.listdir(path+label)):\n",
    "        try:\n",
    "            face = detect_faces(path+label+'/'+image)\n",
    "            img = imageio.imread(path+label+'/'+image)\n",
    "            cropped = img[face[0][1]:face[2][1], face[0][0]:face[1][0],:]\n",
    "\n",
    "            ### make folder and save picture in that directory\n",
    "            saveDir = path+label+\"_cropped\"\n",
    "            try:\n",
    "                if not(os.path.isdir(saveDir)):\n",
    "                    os.makedirs(os.path.join(saveDir))\n",
    "            except OSError as e:\n",
    "                if e.errno != errno.EEXIST:\n",
    "                    print(\"Failed to create directory!!!!!\")\n",
    "                    raise\n",
    "\n",
    "            ### save\n",
    "            im = Image.fromarray(cropped)\n",
    "            im.save(saveDir+'/'+str(i+306)+'.jpg')\n",
    "            if i%100 == 0:\n",
    "                print(str(i)+'/'+str(len(os.listdir(path+label)))+' images cropped')\n",
    "        except:\n",
    "            print(str(i)+'th image '+path+label+'/'+image+' passed~')\n",
    "            pass\n",
    "\n",
    "    print('Total '+str(len(os.listdir(path+label)))+' images cropped')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crop할 이미지들이 들어있는 폴더\n",
    "path = \"/Users/jungyeonkoh/Desktop/YAI/Crawling_Images/\"\n",
    "label= \"써니\"\n",
    "\n",
    "crop_face(path, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 언제쓸지모르지만 이미지 array 시각화\n",
    "def show_img(idx):\n",
    "    plt.rcParams[\"figure.figsize\"] = (10, 10) # set figure size\n",
    "    plt.imshow(train[idx])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformation & DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torchvision\n",
    "from torchvision import models, transforms, datasets\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import splitfolders\n",
    "splitfolders.fixed(\"./Crawling_Images\", \"./\", fixed = (0,50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans = transforms.Compose([transforms.Resize((96,96)), transforms.ToTensor(), \n",
    "                            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 50\n",
    "train_directory = \"/Users/jungyeonkoh/Desktop/YAI/train\"\n",
    "test_directory = \"/Users/jungyeonkoh/Desktop/YAI/test\"\n",
    "\n",
    "data = {\"train\": datasets.ImageFolder(root = train_directory, transform = trans),\n",
    "        \"test\": datasets.ImageFolder(root = test_directory, transform = trans)}\n",
    "\n",
    "idx_to_class = {v : k for k, v in data[\"train\"].class_to_idx.items()}\n",
    "\n",
    "train_data_loader = DataLoader(data[\"train\"], batch_size = batch_size, shuffle = True)\n",
    "test_data_loader = DataLoader(data[\"test\"], batch_size = batch_size, shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN 모델 구축 및 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import google.colab\n",
    "from google.colab import drive\n",
    "\n",
    "drive.mount(\"/content/drive\")\n",
    "os.chdir(\"/content/drive/My Drive\")\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN 구현: Resnet50\n",
    "model = models.resnet50(num_classes = 8)\n",
    "model = model.to(device)\n",
    "\n",
    "print(model)\n",
    "\n",
    "# init\n",
    "learning_rate = 0.002\n",
    "batch_size = 15\n",
    "epoch = 20\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 학습\n",
    "train_data_size = len(data[\"train\"])\n",
    "history = []\n",
    "\n",
    "for i in range(epoch):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    train_acc = 0.0\n",
    "\n",
    "    for num, (inputs, labels) in enumerate(train_data_loader):\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_func(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        #  label값과 prediction값 비교\n",
    "        val, predictions = torch.max(outputs.data, 1)\n",
    "        correct_counts = predictions.eq(labels.data.view_as(predictions))\n",
    "\n",
    "        # train_loss, train_accuracy\n",
    "        acc = torch.mean(correct_counts.type(torch.FloatTensor))\n",
    "        train_acc += acc.item() * inputs.size(0)\n",
    "\n",
    "        print(\"Batch Number: {}, Training Loss: {:.4f}, Accuracy: {:.4f}\".format(num, loss.item(), acc.item()))\n",
    "\n",
    "    avg_train_loss = train_loss / train_data_size\n",
    "    avg_train_acc = train_acc / train_data_size\n",
    "    history.append([avg_train_loss, avg_train_acc])\n",
    "    print(\"Epoch: {}, Training Loss: {:.4f}, Accuracy: {:.4f}\".format(i, avg_train_loss, avg_train_acc))\n",
    "\n",
    "print(\"학습 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualization\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "h = np.array(history)\n",
    "\n",
    "plt.plot(h[:,0])\n",
    "plt.xlabel(\"Epoch Number\")\n",
    "plt.ylabel(\"avg_train_loss\")\n",
    "plt.show()\n",
    "\n",
    "plt.plot(h[:,1])\n",
    "plt.xlabel(\"Epoch Number\")\n",
    "plt.ylabel(\"avg_train_accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_data를 통한 검증\n",
    "\n",
    "test_acc = 0.0\n",
    "test_loss = 0.0\n",
    "test_data_size = len(data[\"test\"])\n",
    "\n",
    "with torch.no_grad():\n",
    "  model.eval()\n",
    "\n",
    "  for num, (inputs, labels) in enumerate(test_data_loader):\n",
    "    inputs = inputs.to(device)\n",
    "    labels = labels.to(device)\n",
    "\n",
    "    outputs = model(inputs)\n",
    "    loss = loss_func(outputs, labels)\n",
    "    test_loss += loss.item() * inputs.size(0)\n",
    "    val, predictions = torch.max(outputs.data, 1)\n",
    "    correct_counts = predictions.eq(labels.data.view_as(predictions))\n",
    "\n",
    "    acc = torch.mean(correct_counts.type(torch.FloatTensor))\n",
    "    test_acc += acc.item() * inputs.size(0)\n",
    "\n",
    "    print(\"Test Batch Number: {}, Test Loss: {:.4f}, Accuracy: {:.4f}\".format(num, loss.item(), acc.item()))\n",
    "  \n",
    "  avg_test_loss = test_loss / test_data_size\n",
    "  avg_test_acc = test_acc / test_data_size\n",
    "\n",
    "  print(\"Test Accuracy: \" + str(avg_test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 개별 파일에 대한 예측\n",
    "\n",
    "test_image_path = \"./test/윤아/140.jpg\"\n",
    "test_image = Image.open(test_image_path)\n",
    "plt.imshow(test_image)\n",
    "\n",
    "test_image_tensor = trans(test_image)\n",
    "test_image_tensor = test_image_tensor.view(1,3,96,96).cuda()\n",
    "\n",
    "with torch.no_grad():\n",
    "  model.eval()\n",
    "  out = model(test_image_tensor)\n",
    "  ps = torch.exp(out)\n",
    "  topk, topclass = ps.topk(3, dim = 1)\n",
    "  for i in range(3):\n",
    "    print(\"Prediction \", i + 1, \": \", idx_to_class[topclass.cpu().numpy()[0][i]], \", Score: \", topk.cpu().numpy()[0][i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
